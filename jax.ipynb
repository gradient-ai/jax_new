{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b23e11d4-1770-4fc4-aeb5-9819fe3bf8f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T06:29:09.520602Z",
     "iopub.status.busy": "2024-05-01T06:29:09.520333Z",
     "iopub.status.idle": "2024-05-01T06:30:04.289317Z",
     "shell.execute_reply": "2024-05-01T06:30:04.287988Z",
     "shell.execute_reply.started": "2024-05-01T06:29:09.520575Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://storage.googleapis.com/jax-releases/jax_cuda_releases.html\n",
      "Requirement already satisfied: jax[cuda12_pip] in /usr/local/lib/python3.9/dist-packages (0.4.1)\n",
      "Collecting jax[cuda12_pip]\n",
      "  Using cached jax-0.4.26-py3-none-any.whl (1.9 MB)\n",
      "Requirement already satisfied: numpy>=1.22 in /usr/local/lib/python3.9/dist-packages (from jax[cuda12_pip]) (1.23.4)\n",
      "Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.9/dist-packages (from jax[cuda12_pip]) (1.9.2)\n",
      "Collecting ml-dtypes>=0.2.0\n",
      "  Downloading ml_dtypes-0.4.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m79.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: opt-einsum in /usr/local/lib/python3.9/dist-packages (from jax[cuda12_pip]) (3.3.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.6 in /usr/local/lib/python3.9/dist-packages (from jax[cuda12_pip]) (6.0.0)\n",
      "Collecting nvidia-cudnn-cu12<9.0,>=8.9.2.26\n",
      "  Downloading nvidia_cudnn_cu12-8.9.7.29-py3-none-manylinux1_x86_64.whl (704.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m704.7/704.7 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nvjitlink-cu12>=12.1.105\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m66.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cublas-cu12>=12.1.3.1\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-cupti-cu12>=12.1.105\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m92.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cufft-cu12>=11.0.2.54\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-runtime-cu12>=12.1.105\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m88.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting jaxlib==0.4.26+cuda12.cudnn89\n",
      "  Downloading https://storage.googleapis.com/jax-releases/cuda12/jaxlib-0.4.26%2Bcuda12.cudnn89-cp39-cp39-manylinux2014_x86_64.whl (144.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.2/144.2 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusolver-cu12>=11.4.5.107\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusparse-cu12>=12.1.0.106\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nccl-cu12>=2.18.1\n",
      "  Downloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-nvcc-cu12>=12.1.105\n",
      "  Downloading nvidia_cuda_nvcc_cu12-12.4.131-py3-none-manylinux2014_x86_64.whl (22.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.3/22.3 MB\u001b[0m \u001b[31m71.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata>=4.6->jax[cuda12_pip]) (3.11.0)\n",
      "Collecting nvidia-cuda-nvrtc-cu12\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m69.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-nvcc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, ml-dtypes, nvidia-cusparse-cu12, nvidia-cudnn-cu12, jaxlib, jax, nvidia-cusolver-cu12\n",
      "  Attempting uninstall: jaxlib\n",
      "    Found existing installation: jaxlib 0.4.1+cuda11.cudnn82\n",
      "    Uninstalling jaxlib-0.4.1+cuda11.cudnn82:\n",
      "      Successfully uninstalled jaxlib-0.4.1+cuda11.cudnn82\n",
      "  Attempting uninstall: jax\n",
      "    Found existing installation: jax 0.4.1\n",
      "    Uninstalling jax-0.4.1:\n",
      "      Successfully uninstalled jax-0.4.1\n",
      "Successfully installed jax-0.4.26 jaxlib-0.4.26+cuda12.cudnn89 ml-dtypes-0.4.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvcc-cu12-12.4.131 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-8.9.7.29 nvidia-cufft-cu12-11.2.1.3 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U \"jax[cuda12_pip]\" -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f890d73e-c06d-43d5-9cf0-c34f20070ddc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T06:30:16.476215Z",
     "iopub.status.busy": "2024-05-01T06:30:16.475935Z",
     "iopub.status.idle": "2024-05-01T06:30:17.410024Z",
     "shell.execute_reply": "2024-05-01T06:30:17.408977Z",
     "shell.execute_reply.started": "2024-05-01T06:30:16.476188Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed May  1 06:30:17 2024       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 525.116.04   Driver Version: 525.116.04   CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA RTX A4000    On   | 00000000:00:05.0 Off |                  Off |\n",
      "| 41%   35C    P8    17W / 140W |      1MiB / 16376MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bf1aebd-b5f3-4db8-8016-14a5d0eeda76",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T06:30:24.746161Z",
     "iopub.status.busy": "2024-05-01T06:30:24.745901Z",
     "iopub.status.idle": "2024-05-01T06:30:25.145147Z",
     "shell.execute_reply": "2024-05-01T06:30:25.144292Z",
     "shell.execute_reply.started": "2024-05-01T06:30:24.746150Z"
    }
   },
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2afd0968-692f-4f04-9684-8483333f98e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-30T10:55:05.364885Z",
     "iopub.status.busy": "2024-04-30T10:55:05.364129Z",
     "iopub.status.idle": "2024-04-30T10:55:07.384920Z",
     "shell.execute_reply": "2024-04-30T10:55:07.384340Z",
     "shell.execute_reply.started": "2024-04-30T10:55:05.364840Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-30 10:55:07.121811: W external/xla/xla/service/gpu/nvptx_compiler.cc:718] The NVIDIA driver's CUDA version is 12.0 which is older than the ptxas CUDA version (12.4.131). Because the driver is older than the ptxas version, XLA is disabling parallel compilation, which may slow down compilation. You should update your NVIDIA driver or use the NVIDIA-provided CUDA forward compatibility packages.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3], dtype=int32), Array([0, 1, 2, 3], dtype=int32))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L = [0, 1, 2, 3]\n",
    "x_np = np.array(L, dtype=np.int32)\n",
    "x_jnp = jnp.array(L, dtype=jnp.int32)\n",
    "\n",
    "x_np, x_jnp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba70988d-66b0-48fe-8a6d-580cd2e34316",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-30T10:55:22.477166Z",
     "iopub.status.busy": "2024-04-30T10:55:22.476862Z",
     "iopub.status.idle": "2024-04-30T10:55:22.580075Z",
     "shell.execute_reply": "2024-04-30T10:55:22.579364Z",
     "shell.execute_reply.started": "2024-04-30T10:55:22.477142Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Array([0, 2, 4, 6], dtype=int32),\n",
       " Array([1, 2, 3, 4], dtype=int32),\n",
       " Array([ 1,  4,  7, 10], dtype=int32))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = x_jnp*2\n",
    "x2 = x_jnp+1\n",
    "x3 = x1 + x2\n",
    "\n",
    "x1, x2, x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c07afe60-ad9a-4a49-a789-1c89e0d8a370",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-30T10:57:29.615333Z",
     "iopub.status.busy": "2024-04-30T10:57:29.614754Z",
     "iopub.status.idle": "2024-04-30T10:57:37.550841Z",
     "shell.execute_reply": "2024-04-30T10:57:37.550216Z",
     "shell.execute_reply.started": "2024-04-30T10:57:29.615303Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 41 µs, sys: 28 µs, total: 69 µs\n",
      "Wall time: 74.6 µs\n",
      "CPU times: user 139 ms, sys: 42.2 ms, total: 181 ms\n",
      "Wall time: 216 ms\n",
      "9.3 ms ± 43.1 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import random\n",
    "\n",
    "key = random.PRNGKey(0)\n",
    "size = 5000\n",
    "\n",
    "x = random.normal(key, (size, size)).astype(jnp.float32)\n",
    "%time x_jax = jax.device_put(x)\n",
    "%time jnp.dot(x_jax, x_jax.T).block_until_ready()\n",
    "%timeit jnp.dot(x_jax, x_jax.T).block_until_ready()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fdb29c90-af57-4437-b511-db1e3710cc8d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-30T10:58:24.160032Z",
     "iopub.status.busy": "2024-04-30T10:58:24.159208Z",
     "iopub.status.idle": "2024-04-30T10:58:31.539351Z",
     "shell.execute_reply": "2024-04-30T10:58:31.538721Z",
     "shell.execute_reply.started": "2024-04-30T10:58:24.160003Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 45 µs, sys: 27 µs, total: 72 µs\n",
      "Wall time: 78 µs\n",
      "CPU times: user 68.1 ms, sys: 91 µs, total: 68.2 ms\n",
      "Wall time: 83.9 ms\n",
      "88.1 µs ± 3.71 µs per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "from jax import grad, jit\n",
    "\n",
    "key = random.PRNGKey(0)\n",
    "\n",
    "def selu_np(x, alpha=1.67, lmbda=1.05):\n",
    "  return lmbda * np.where(x > 0, x, alpha * np.exp(x) - alpha)\n",
    "\n",
    "def selu_jax(x, alpha=1.67, lmbda=1.05):\n",
    "  return lmbda * jnp.where(x > 0, x, alpha * jnp.exp(x) - alpha)\n",
    "\n",
    "x = random.normal(key, (1000000,))\n",
    "\n",
    "selu_jax_jit = jit(selu_jax)\n",
    "%time x_jax = jax.device_put(x) \n",
    "%time selu_jax_jit(x_jax).block_until_ready() \n",
    "%timeit selu_jax_jit(x_jax).block_until_ready()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3176bdf-c7a8-4388-8e82-10c0a9c7acfa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T06:31:31.739572Z",
     "iopub.status.busy": "2024-05-01T06:31:31.738891Z",
     "iopub.status.idle": "2024-05-01T06:31:36.855568Z",
     "shell.execute_reply": "2024-05-01T06:31:36.854830Z",
     "shell.execute_reply.started": "2024-05-01T06:31:31.739546Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CUDA backend failed to initialize: Unable to use CUDA because of the following issues with CUDA components:\n",
      "Outdated cuDNN installation found.\n",
      "Version JAX was built against: 8906\n",
      "Minimum supported: 8900\n",
      "Installed version: 8302\n",
      "The local installation version must be no lower than 8900. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240 ms ± 1.85 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "29.5 ms ± 475 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "import jax.numpy as jnp\n",
    "from jax import grad, jit, vmap\n",
    "from jax import random\n",
    "import numpy as np\n",
    "\n",
    "def fn(x):\n",
    "    return x + x*x + x*x*x + x*x*x*x\n",
    "\n",
    "x_np = np.random.randn(5000,5000).astype(dtype='float32')\n",
    "x_jnp = jnp.array(x_np)  #numpy- >jax DeviceArray\n",
    "\n",
    "%timeit fn(x_np)\n",
    "%timeit jit(fn)(x_jnp).block_until_ready()\n",
    "\n",
    "#Microsecond is one millionth of a second. Millisecond is one thousandth of a second.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b80ba1c-ca57-4a13-b4ad-8cc84d229379",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T06:30:36.155216Z",
     "iopub.status.busy": "2024-05-01T06:30:36.154604Z",
     "iopub.status.idle": "2024-05-01T06:30:36.746674Z",
     "shell.execute_reply": "2024-05-01T06:30:36.745638Z",
     "shell.execute_reply.started": "2024-05-01T06:30:36.155187Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "770ab1c5-da61-4a6f-a093-00d28350d8a1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T06:39:41.744962Z",
     "iopub.status.busy": "2024-05-01T06:39:41.744654Z",
     "iopub.status.idle": "2024-05-01T06:39:42.707644Z",
     "shell.execute_reply": "2024-05-01T06:39:42.706872Z",
     "shell.execute_reply.started": "2024-05-01T06:39:41.744938Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JAX execution time: 0.7215843200683594 seconds\n",
      "PyTorch execution time: 0.01124262809753418 seconds\n",
      "numpy execution time: 0.015349864959716797 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import jax.numpy as jnp\n",
    "from jax import jit\n",
    "import torch\n",
    "\n",
    "# Define JAX matrix multiplication function\n",
    "def jax_matmul(A, B):\n",
    "    return jnp.dot(A, B)\n",
    "\n",
    "# Add JIT compilation for performance\n",
    "jax_matmul_jit = jit(jax_matmul)\n",
    "\n",
    "# Define PyTorch matrix multiplication function\n",
    "def torch_matmul(A, B):\n",
    "    return torch.matmul(A, B)\n",
    "\n",
    "# Generate large matrices\n",
    "matrix_size = 1000\n",
    "#A_jax = jnp.random.randn(matrix_size, matrix_size)\n",
    "A_np = np.random.randn(matrix_size,matrix_size).astype(dtype='float32')\n",
    "A_jax = jnp.array(x_np)\n",
    "\n",
    "#B_jax = jnp.random.randn(matrix_size, matrix_size)\n",
    "B_np = np.random.randn(matrix_size,matrix_size).astype(dtype='float32')\n",
    "B_jax = jnp.array(x_np)\n",
    "\n",
    "A_torch = torch.randn(matrix_size, matrix_size)\n",
    "B_torch = torch.randn(matrix_size, matrix_size)\n",
    "\n",
    "# Measure execution time for JAX\n",
    "start_time = time.time()\n",
    "result_jax = jax_matmul_jit(A_jax, B_jax)\n",
    "jax_execution_time = time.time() - start_time\n",
    "\n",
    "# Measure execution time for PyTorch\n",
    "start_time = time.time()\n",
    "result_torch = torch_matmul(A_torch, B_torch)\n",
    "torch_execution_time = time.time() - start_time\n",
    "\n",
    "# Measure execution time for numpy\n",
    "start_time = time.time()\n",
    "result_numpy = np.dot(A_np, B_np)\n",
    "numpy_execution_time = time.time() - start_time\n",
    "\n",
    "print(\"JAX execution time:\", jax_execution_time, \"seconds\")\n",
    "print(\"PyTorch execution time:\", torch_execution_time, \"seconds\")\n",
    "print(\"numpy execution time:\", numpy_execution_time, \"seconds\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b493a2aa-34b3-4029-bc8c-8004af797705",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T06:53:30.403156Z",
     "iopub.status.busy": "2024-05-01T06:53:30.402365Z",
     "iopub.status.idle": "2024-05-01T06:53:30.407025Z",
     "shell.execute_reply": "2024-05-01T06:53:30.406426Z",
     "shell.execute_reply.started": "2024-05-01T06:53:30.403125Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import jax.numpy as jnp\n",
    "from jax import jit, random\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "04c7b473-1f43-4034-a90f-ad8ebbb938fa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T06:50:23.967740Z",
     "iopub.status.busy": "2024-05-01T06:50:23.967420Z",
     "iopub.status.idle": "2024-05-01T06:50:24.342903Z",
     "shell.execute_reply": "2024-05-01T06:50:24.342134Z",
     "shell.execute_reply.started": "2024-05-01T06:50:23.967716Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JAX execution time: 0.00592041015625 seconds\n",
      "PyTorch execution time: 0.017140865325927734 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define JAX matrix multiplication function\n",
    "def jax_matmul(A, B):\n",
    "    return jnp.dot(A, B)\n",
    "\n",
    "# Add JIT compilation for performance\n",
    "jax_matmul_jit = jit(jax_matmul)\n",
    "\n",
    "# Define PyTorch matrix multiplication function\n",
    "def torch_matmul(A, B):\n",
    "    return torch.matmul(A, B)\n",
    "\n",
    "# Generate large matrices\n",
    "matrix_size = 1000\n",
    "key = random.PRNGKey(0)\n",
    "A_jax = random.normal(key, (matrix_size, matrix_size))\n",
    "B_jax = random.normal(key, (matrix_size, matrix_size))\n",
    "A_torch = torch.randn(matrix_size, matrix_size)\n",
    "B_torch = torch.randn(matrix_size, matrix_size)\n",
    "\n",
    "# Warm-up runs\n",
    "for _ in range(10):\n",
    "    jax_matmul_jit(A_jax, B_jax)\n",
    "    torch_matmul(A_torch, B_torch)\n",
    "\n",
    "# Measure execution time for JAX\n",
    "start_time = time.time()\n",
    "result_jax = jax_matmul_jit(A_jax, B_jax).block_until_ready()\n",
    "jax_execution_time = time.time() - start_time\n",
    "\n",
    "# Measure execution time for PyTorch\n",
    "start_time = time.time()\n",
    "result_torch = torch_matmul(A_torch, B_torch)\n",
    "torch_execution_time = time.time() - start_time\n",
    "\n",
    "print(\"JAX execution time:\", jax_execution_time, \"seconds\")\n",
    "print(\"PyTorch execution time:\", torch_execution_time, \"seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "844f4695-f1e2-4ee2-a51b-733c27977cee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T06:55:24.000530Z",
     "iopub.status.busy": "2024-05-01T06:55:23.999963Z",
     "iopub.status.idle": "2024-05-01T06:55:24.232701Z",
     "shell.execute_reply": "2024-05-01T06:55:24.232085Z",
     "shell.execute_reply.started": "2024-05-01T06:55:24.000503Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum (JAX): -1.4999998\n",
      "Execution time (JAX): 0.22281455993652344 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import jax.numpy as jnp\n",
    "from jax import grad, jit\n",
    "\n",
    "# Define the function to minimize\n",
    "def f(x):\n",
    "    return x**2 + 3*x + 5\n",
    "\n",
    "# Define the gradient of the function\n",
    "grad_f = grad(f)\n",
    "\n",
    "# Initial guess for the minimum\n",
    "x = 0.0\n",
    "\n",
    "# Learning rate\n",
    "learning_rate = 0.1\n",
    "\n",
    "# Warm-up run\n",
    "x -= learning_rate * grad_f(x)\n",
    "\n",
    "# Perform gradient descent and measure time\n",
    "start_time = time.time()\n",
    "for i in range(100):\n",
    "    x -= learning_rate * grad_f(x)\n",
    "jax_execution_time = time.time() - start_time\n",
    "\n",
    "print(\"Minimum (JAX):\", x)\n",
    "print(\"Execution time (JAX):\", jax_execution_time, \"seconds\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "872842d1-7aaf-4952-bf4c-955762b38793",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T06:55:41.955341Z",
     "iopub.status.busy": "2024-05-01T06:55:41.954682Z",
     "iopub.status.idle": "2024-05-01T06:55:41.969079Z",
     "shell.execute_reply": "2024-05-01T06:55:41.968357Z",
     "shell.execute_reply.started": "2024-05-01T06:55:41.955313Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum (PyTorch): -1.499999761581421\n",
      "Execution time (PyTorch): 0.007425785064697266 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch\n",
    "\n",
    "# Define the function to minimize\n",
    "def f(x):\n",
    "    return x**2 + 3*x + 5\n",
    "\n",
    "# Convert the function to a PyTorch tensor\n",
    "x = torch.tensor([0.0], requires_grad=True)\n",
    "\n",
    "# Learning rate\n",
    "learning_rate = 0.1\n",
    "\n",
    "# Warm-up run\n",
    "y = f(x)\n",
    "y.backward()\n",
    "with torch.no_grad():\n",
    "    x -= learning_rate * x.grad\n",
    "x.grad.zero_()\n",
    "\n",
    "# Perform gradient descent and measure time\n",
    "start_time = time.time()\n",
    "for i in range(100):\n",
    "    y = f(x)\n",
    "    y.backward()\n",
    "    with torch.no_grad():\n",
    "        x -= learning_rate * x.grad\n",
    "    x.grad.zero_()\n",
    "torch_execution_time = time.time() - start_time\n",
    "\n",
    "print(\"Minimum (PyTorch):\", x.item())\n",
    "print(\"Execution time (PyTorch):\", torch_execution_time, \"seconds\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f381f1c4-afa4-4c75-8e85-574cd7b08dd5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T07:00:24.435380Z",
     "iopub.status.busy": "2024-05-01T07:00:24.434787Z",
     "iopub.status.idle": "2024-05-01T07:00:24.443590Z",
     "shell.execute_reply": "2024-05-01T07:00:24.442858Z",
     "shell.execute_reply.started": "2024-05-01T07:00:24.435356Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(6., dtype=float32, weak_type=True)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = lambda x:x**2\n",
    "f(3)\n",
    "jax.grad(f)(3.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "32ed0d86-9811-4957-9dfe-5d5fdaea7f8e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T07:03:45.033161Z",
     "iopub.status.busy": "2024-05-01T07:03:45.032753Z",
     "iopub.status.idle": "2024-05-01T07:03:45.038618Z",
     "shell.execute_reply": "2024-05-01T07:03:45.037952Z",
     "shell.execute_reply.started": "2024-05-01T07:03:45.033135Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor(\n",
    "    3.0,\n",
    "    requires_grad = True\n",
    ")\n",
    "\n",
    "y = x**2\n",
    "y.backward()\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b2808cb0-887e-4bdf-a6e2-a2891b5eafbc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T07:05:15.274478Z",
     "iopub.status.busy": "2024-05-01T07:05:15.274215Z",
     "iopub.status.idle": "2024-05-01T07:05:15.283561Z",
     "shell.execute_reply": "2024-05-01T07:05:15.282528Z",
     "shell.execute_reply.started": "2024-05-01T07:05:15.274457Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Derivative (JAX) at x = 2.0 : 7.0\n"
     ]
    }
   ],
   "source": [
    "import jax.numpy as jnp\n",
    "from jax import grad\n",
    "\n",
    "# Define the function to differentiate\n",
    "def f(x):\n",
    "    return x**2 + 3*x + 5\n",
    "\n",
    "# Define the derivative of the function using JAX's grad function\n",
    "df_dx = grad(f)\n",
    "\n",
    "# Test the derivative at a specific point\n",
    "x_value = 2.0\n",
    "derivative_value = df_dx(x_value)\n",
    "print(\"Derivative (JAX) at x =\", x_value, \":\", derivative_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8e341da3-62e0-446d-9d76-bd5a23cf1088",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T07:05:26.869311Z",
     "iopub.status.busy": "2024-05-01T07:05:26.869037Z",
     "iopub.status.idle": "2024-05-01T07:05:26.874962Z",
     "shell.execute_reply": "2024-05-01T07:05:26.874091Z",
     "shell.execute_reply.started": "2024-05-01T07:05:26.869289Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Derivative (PyTorch) at x = 2.0 : 7.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Define the function to differentiate\n",
    "def f(x):\n",
    "    return x**2 + 3*x + 5\n",
    "\n",
    "# Convert the function to a PyTorch tensor\n",
    "x = torch.tensor([2.0], requires_grad=True)\n",
    "\n",
    "# Calculate the derivative using PyTorch's autograd mechanism\n",
    "y = f(x)\n",
    "y.backward()\n",
    "derivative_value = x.grad.item()\n",
    "print(\"Derivative (PyTorch) at x =\", x.item(), \":\", derivative_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c2043d-f93a-4e10-8402-338e79bdad33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458c2453-72af-4cad-a7c1-32c377714d82",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
